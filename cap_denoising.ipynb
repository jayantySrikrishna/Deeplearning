{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":false},"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pathlib\nimport cv2\nimport numpy as np\nimport os\n\n\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# instantiating the model in the strategy scope creates the model on the TPU\n\nAUTO = tf.data.experimental.AUTOTUNE\n\nIMAGE_SIZE = [331, 331]\n\nbatch_size = 16 * tpu_strategy.num_replicas_in_sync\n\ndata_dir = \"../input/capillaroscopy/Images/*.jpg\"\n'''\nvalidation_split = 0.19\nfilenames = tf.io.gfile.glob(data_dir)\nsplit = len(filenames) - int(len(filenames) * validation_split)\ntrain_fns = filenames[:split]\nvalidation_fns = filenames[split:]\n\nprint(train_fns)\n'''\ndata_path = pathlib.Path(data_dir)\n\nprint('Database Directory')\nprint(data_path)\n\n#image_count = len(list(data_path.glob('*.jpg')))\n#print(image_count)\n\nretinal_dataset = sorted(list(data_path.glob('*')))\n\nbatch_size = 8\n\n\n#Preprocessing\ntraining_data = []\ndef read_image(path):\n    for img in path:\n        im_path = str(img)\n        img_array = cv2.imread(im_path)\n        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n        img_array = cv2.resize(img_array, dsize=(576, 544), interpolation=cv2.INTER_AREA)\n        training_data.append(img_array)\n        if len(training_data)>400:\n            break\n\nread_image(retinal_dataset) \n\n\nX = np.array(training_data)\nprint(X.dtype)\nX = X.astype('float32') / 255.0\nprint(X.dtype)\n\n\nIMG_SHAPE = X.shape[1:]\nfrom sklearn.model_selection import train_test_split\n\ntrain_imgs, test_imgs = train_test_split(X, test_size =0.2)\n\n\nnoise_factor = 0.1\nx_train_noisy = train_imgs + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_imgs.shape) \nx_test_noisy = test_imgs + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_imgs.shape) \n\ntrain_noisy = np.clip(x_train_noisy, 0.0, 1.0)\ntest_noisy = np.clip(x_test_noisy, 0.0, 1.0)\n# plot image example from training images\nplt.imshow(train_imgs[1])\nplt.show()\n\nplt.imshow(train_noisy[1])\nplt.show()\n'''\ndef add_noise(img):\n        VARIABILITY = 50\n        deviation = VARIABILITY*random.random()\n        noise = np.random.normal(0, deviation, img.shape)\n        img += noise\n        np.clip(img, 0.0, 255.0)\n        return img\n#Data Generator\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=40,\n                                                               width_shift_range=0.2,\n                                                               height_shift_range=0.2,\n                                                               zoom_range=0.4,\n                                                               validation_split=0.2, \n                                                               preprocessing_function=add_noise)\ntrain_generator = train_datagen.flow_from_directory(data_dir, batch_size=8, color_mode='rgb', target_size=(576, 544), class_mode=None, subset='training')\nvalidation_generator = train_datagen.flow_from_directory(data_dir, batch_size=8, color_mode='rgb', target_size=(576, 544), class_mode=None, subset='validation')\n#image_count = len(list(data_path.glob('*.jpg')))\n\n    history = auto_encoder.fit(x=train_generator, steps_per_epoch=train_generator.samples,\n                              validation_data=validation_generator,\n                              validation_steps=validation_generator.samples,\n                              epochs=10)\n'''\nwith tpu_strategy.scope():\n    input_img = tf.keras.layers.Input(IMG_SHAPE)\n    l1 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(input_img)\n    l2 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l1)\n    r1 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l2)\n    r2 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(r1)\n    l3 = tf.keras.layers.MaxPool2D(padding='same')(r2)\n\n    l4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l3)\n    l5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l4)\n    r4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l5)\n    r5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(r4)\n    l6 = tf.keras.layers.MaxPool2D(padding='same')(r5)\n\n    la = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l6)\n    lb = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(la)\n    ra = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(lb)\n    rb = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(ra)\n    lc = tf.keras.layers.MaxPool2D(padding='same')(rb)\n\n    \n    l7 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(lc)\n\n    \n    ld = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, padding='same', strides=2)(l7)\n    le = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(ld)\n    lf = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(le)\n    rd = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(lf)\n    re = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(rd)\n    lg = tf.keras.layers.add([re, rb])\n    \n    #l8 = tf.keras.layers.UpSampling2D()(l7)\n    l8 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, padding='same', strides=2)(lg)\n    l9 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l8)\n    l10 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l9)\n    r9 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l10)\n    r10 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(r9)\n    l11 = tf.keras.layers.add([r10, r5])\n    #l11 = r10\n    l12 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, padding='same', strides=2)(l11)\n    l13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l12)\n    l14 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l13)\n    r14 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l14)\n    r15 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(r14)\n    l15 = tf.keras.layers.add([r15, r2])\n    #l15 = r15\n    c1 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(l15)\n    c2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', use_bias=True, activity_regularizer=tf.keras.regularizers.l1(10e-10))(c1)\n    decoded_image = tf.keras.layers.Conv2D(3, (3, 3), padding='same', kernel_initializer=tf.initializers.GlorotUniform, activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-10))(c2)\n\n    from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n    from keras.models import Sequential, Model\n\n    # training process params\n    auto_encoder = Model(inputs=(input_img), outputs=decoded_image)\n   # auto_encoder.load_weights(retinal_model)\n    auto_encoder.compile(optimizer='adamax', loss='mse')\n\n    print(auto_encoder.summary())\n\n    history = auto_encoder.fit(x=train_noisy, y=train_imgs, epochs=50,\n                validation_data=[test_noisy, test_imgs])\n\n\nimport numpy as np\npredictions = np.clip(auto_encoder.predict(test_noisy), 0.0, 1.0)\nplt.imshow(test_noisy[10])\nplt.show()\nplt.imshow(predictions[10])\nplt.show()\nfor i in range(20, 35):\n    arr = np.uint8(test_noisy[i]*255)\n    test = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n    pred = cv2.cvtColor(predictions[i], cv2.COLOR_RGB2BGR)\n    cv2.imwrite(\"noisy_\"+str(i)+\".png\", test)\n    cv2.imwrite(\"denoised_\"+str(i)+\".png\", 255*pred)\n\n#import h5py\n#auto_encoder.save_weights('model_save_path.h5')","execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}